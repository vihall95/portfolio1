{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "## Convnet on CIFAR10 Small Image Classification\n",
    "### Victoria Hall\n",
    "### 7.16.2022\n",
    "\n",
    "This project sets to build a convnet on CIFAR10 data available through Keras. Parameters are tested for best model building.\n",
    "1. Convnet without dropout or data-augmentation\n",
    "2. Convnet with dropout and data-augmentation\n",
    "\n",
    "**Resources**\n",
    "1. https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
    "2. Deep Learning with Python, Francois, 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Convnet without dropout or data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and prepping data\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "# load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    " \n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    #output part of the model\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    #compiling\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 74.290\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original model without dropout and image augementationn is 74% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convnet with data augmentation and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-81464aa20ac5>:89: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "> 87.200\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    " \n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    " \n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    " \n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\t# prepare iterator\n",
    "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "\t# fit model\n",
    "\tsteps = int(trainX.shape[0] / 64)\n",
    "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=200, validation_data=(testX, testY), verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with dropout and image augementation is 87% accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
